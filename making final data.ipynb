{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5728d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1470d872",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['16_with_adress.csv', '6_with_adress.csv', '51_with_adress.csv', '48_with_adress.csv', '32_with_adress.csv', '47_with_adress.csv', '9_with_adress.csv', '19_with_adress.csv', '24_with_adress.csv', '59_with_adress.csv', '23_with_adress.csv', '40_with_adress.csv', '35_with_adress.csv', '1_with_adress.csv', '11_with_adress.csv', 'Untitled.ipynb', '58_with_adress.csv', '34_with_adress.csv', '10_with_adress.csv', '57_with_adress.csv', '50_with_adress.csv', '17_with_adress.csv', '33_with_adress.csv', '46_with_adress.csv', '8_with_adress.csv', '18_with_adress.csv', '25_with_adress.csv', '43_with_adress.csv', '20_with_adress.csv', '2_with_adress.csv', '55_with_adress.csv', '36_with_adress.csv', '31_with_adress.csv', '52_with_adress.csv', '5_with_adress.csv', '15_with_adress.csv', '28_with_adress.csv', '60_with_adress.csv', '44_with_adress.csv', '4_with_adress.csv', '14_with_adress.csv', '53_with_adress.csv', '26_with_adress.csv', '45_with_adress.csv', '42_with_adress.csv', '21_with_adress.csv', '54_with_adress.csv', '13_with_adress.csv', '3_with_adress.csv', '37_with_adress.csv']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir('./test_map'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a52943a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16_with_adress.csv\n",
      "6_with_adress.csv\n",
      "51_with_adress.csv\n",
      "48_with_adress.csv\n",
      "32_with_adress.csv\n",
      "47_with_adress.csv\n",
      "9_with_adress.csv\n",
      "19_with_adress.csv\n",
      "24_with_adress.csv\n",
      "59_with_adress.csv\n",
      "23_with_adress.csv\n",
      "40_with_adress.csv\n",
      "35_with_adress.csv\n",
      "1_with_adress.csv\n",
      "11_with_adress.csv\n",
      "Untitled.ipynb\n"
     ]
    },
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 4, saw 2\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_name \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./test_map\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(file_name)\n\u001b[0;32m----> 4\u001b[0m     data\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./test_map\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     data\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnnamed: 0\u001b[39m\u001b[38;5;124m'\u001b[39m,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:617\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1748\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1741\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m     (\n\u001b[1;32m   1745\u001b[0m         index,\n\u001b[1;32m   1746\u001b[0m         columns,\n\u001b[1;32m   1747\u001b[0m         col_dict,\n\u001b[0;32m-> 1748\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1749\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1750\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1751\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1752\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32mparsers.pyx:843\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:904\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:879\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:890\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:2058\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 4, saw 2\n"
     ]
    }
   ],
   "source": [
    "df=None\n",
    "for file_name in os.listdir('./test_map'):\n",
    "    if not file_name.endwith('csv'):\n",
    "        continue\n",
    "    data=pd.read_csv(os.path.join('./test_map',file_name))\n",
    "    data=data.drop('Unnamed: 0',axis=1)\n",
    "    if df is None:\n",
    "        df=data\n",
    "    else:\n",
    "        df=pd.concat([df,data])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a06dd57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.hall.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6930635",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5c434e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['type']=='vending_machine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0d18bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_data(type_at,hall):\n",
    "\n",
    "    if type_at=='university':\n",
    "        if hall=='Dartmouth College':\n",
    "            return 'home_time'\n",
    "        else: return 'school_time'\n",
    "    elif type_at in ['dormitory', 'house','apartments','residential']:\n",
    "        return 'home_time'\n",
    "    elif type_at in ['college','school','educational_institution']:\n",
    "        return 'school_time'\n",
    "    elif type_at in ['bicycle_parking','parking','bus_stop','pedestrian','primary','cycleway', 'railway_station','car_repair']:\n",
    "        return 'travel_time'\n",
    "    elif type_at in ['beauty','electronics', 'wholesale','interior_decoration','service','retail','florist','bakery']:\n",
    "        return 'shopping'\n",
    "    elif type_at in ['industrial','veterinary','office', 'social_centre','social_facility']:\n",
    "        return 'working'\n",
    "    elif type_at in ['pub','convenience', 'public_bookcase','golf_course','cafe','fast_food','books','bar','clothes', 'pottery', 'hotel','outdoor_seating', 'museum','pitch','sports_centre','library', 'arts_centre', 'grandstand', 'restaurant', 'bench', 'courtyard']:\n",
    "        return 'recreational_activities'\n",
    "    else: return 'orthers'\n",
    "        \n",
    "df['new_type']=df.apply(lambda df: group_data(df['type'],df['hall']),axis=1)\n",
    "df['time_difference']=list(df['time_difference'][1:])+[np.nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1053ba98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.fillna(0)\n",
    "df.new_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b94299",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed5fb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_check=df[df['tnv']==1]\n",
    "data_check['hall']=data_check['hall'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd3ac50",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_check['location_names']=data_check.groupby(['date'])['hall'].transform(','.join)\n",
    "location_names=data_check[['date','location_names']].drop_duplicates().set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82463746",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "def convert_day(time):\n",
    "\n",
    "    time_conv=datetime.strptime(time,'%d:%m:%Y')\n",
    "\n",
    "    time_re=time_conv.strftime(\"%w\")\n",
    "    return time_re\n",
    "def trim(x):\n",
    "    try:\n",
    "        return x.strip()\n",
    "    except: \n",
    "        print(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ee6c71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # change convertdate to '... ' to work this function\n",
    "\n",
    "\n",
    "\n",
    "# data_1=data_check.groupby(['date','new_type'])['time_difference'].sum().to_frame()\n",
    "# data_1=data_1.reset_index()\n",
    "\n",
    "\n",
    "# data_vol_1=None\n",
    "# for date in data_1.date.unique():\n",
    "#     data_show=data_1[data_1['date']==date].set_index(\"new_type\").iloc[:,1].T\n",
    "#     if data_vol_1 is None:\n",
    "#         data_vol_1=data_show\n",
    "#     else:\n",
    "#         data_vol_1=pd.concat([data_vol_1,data_show],axis=1)\n",
    "# data_vol_1=data_vol_1.T\n",
    "# data_vol_1['date']=data_1.date.unique()\n",
    "# data_vol_1['date']=data_vol_1['date']\n",
    "# print(type(data_vol_1['date'][0]))\n",
    "# ls=[]\n",
    "# for date in data_vol_1['date']:\n",
    "#     ls.append(convert_day(date))\n",
    "# data_vol_1['date_in_week']=ls\n",
    "# data_vol_1=data_vol_1.set_index('date')\n",
    "# data_vol_1['volunteer']=[1]*data_vol_1.shape[0]\n",
    "# data_check['location_names']=data_check.groupby(['date'])['hall'].transform(','.join)\n",
    "# location_names=data_check[['date','location_names']].drop_duplicates().set_index('date')\n",
    "# data_vol_1=pd.concat([data_vol_1,location_names],axis=1)\n",
    "# data_vol_1=data_vol_1.fillna(0)                                   \n",
    "# data_vol_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a2ccba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_data=pd.read_csv('./time_learn_in_day.csv')\n",
    "class_data=class_data.set_index('tnv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf64f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tnv in df.tnv.unique():\n",
    "    location_names=None\n",
    "    data_check=df[df['tnv']==tnv]\n",
    "    data_check['date']=data_check['date'].apply(lambda x:trim(x))\n",
    "    data_check['hall']=data_check['hall'].astype(str)\n",
    "    data_tnv=data_check.groupby(['date','new_type'])['time_difference'].sum().to_frame()\n",
    "    data_tnv=data_tnv.reset_index()  \n",
    "    data_check['location_names']=data_check.groupby(['date'])['hall'].transform(','.join)\n",
    "    location_names=data_check[['date','location_names']].drop_duplicates()\n",
    "    \n",
    "    location_names['date']=location_names['date'].apply(lambda x:trim(x))\n",
    "    location_names=location_names.set_index('date')\n",
    "    \n",
    "    \n",
    "    data_vol_tnv=None\n",
    "    for date in data_tnv.date.unique():\n",
    "        data_show=data_tnv[data_tnv['date']==date].set_index(\"new_type\").iloc[:,1].T\n",
    "        if data_vol_tnv is None:\n",
    "            data_vol_tnv=data_show\n",
    "        else:\n",
    "            data_vol_tnv=pd.concat([data_vol_tnv,data_show],axis=1)\n",
    "    data_vol_tnv=data_vol_tnv.T\n",
    "    data_vol_tnv['date']=data_tnv.date.unique()\n",
    "    data_vol_tnv['date']=data_vol_tnv['date']\n",
    "    ls=[]\n",
    "    \n",
    "    \n",
    "    for date in data_vol_tnv['date']:\n",
    "        ls.append(int(convert_day(date))-1)\n",
    "    data_vol_tnv['date_in_week']=ls\n",
    "    data_vol_tnv=data_vol_tnv.set_index('date')\n",
    "    data_vol_tnv['volunteer']=[tnv]*data_vol_tnv.shape[0]\n",
    "    \n",
    "    data_vol_tnv=pd.concat([data_vol_tnv,location_names],axis=1)\n",
    "    data_vol_tnv=data_vol_tnv.fillna(0)                                   \n",
    "    data_vol_tnv.to_csv(f'./final_data_no_cut_class/{tnv}_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17912996",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_cut_class(time,date,tnv):\n",
    "    if date>-1:\n",
    "        try:\n",
    "            learning_schedule=eval(class_data.loc[tnv,'time_learn_day'])\n",
    "\n",
    "            if time < 0.7*float(learning_schedule[date]):\n",
    "                return 1\n",
    "            return 0\n",
    "        except: pass\n",
    "    print('error')\n",
    "    return np.nan\n",
    "def time_to_learn(date,tnv):\n",
    "    if date>-1:\n",
    "        try:\n",
    "            learning_schedule=eval(class_data.loc[tnv,'time_learn_day'])\n",
    "\n",
    "            return (learning_schedule[date])\n",
    "        except: pass\n",
    "    print('error')\n",
    "    return np.nan\n",
    "a=is_cut_class(12,1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b546536",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tnv in df.tnv.unique():\n",
    "    location_names=None\n",
    "    data_check=df[df['tnv']==tnv]\n",
    "    data_check['date']=data_check['date'].apply(lambda x:trim(x))\n",
    "    data_check['hall']=data_check['hall'].astype(str)\n",
    "    data_check['location_names']=data_check.groupby(['date'])['hall'].transform(','.join)\n",
    "    \n",
    "    location_names=data_check[['date','location_names']].drop_duplicates()\n",
    "    location_names['date']=location_names['date'].apply(lambda x:trim(x))\n",
    "    location_names=location_names.set_index('date')\n",
    "    \n",
    "    data_tnv=data_check.groupby(['date','new_type'])['time_difference'].sum().to_frame()\n",
    "    data_tnv=data_tnv.reset_index()\n",
    "    data_vol_tnv=None\n",
    "    for date in data_tnv.date.unique():\n",
    "        data_show=data_tnv[data_tnv['date']==date].set_index(\"new_type\").iloc[:,1].T\n",
    "        if data_vol_tnv is None:\n",
    "            data_vol_tnv=data_show\n",
    "        else:\n",
    "            data_vol_tnv=pd.concat([data_vol_tnv,data_show],axis=1)\n",
    "    data_vol_tnv=data_vol_tnv.T\n",
    "    data_vol_tnv['date']=data_tnv.date.unique()\n",
    "#     data_vol_tnv['date']=data_vol_tnv['date']\n",
    "    ls=[]\n",
    "    for date in data_vol_tnv['date']:\n",
    "        ls.append(int(convert_day(date))-1)\n",
    "    data_vol_tnv['date_in_week']=ls\n",
    "    data_vol_tnv=data_vol_tnv.fillna(0) \n",
    "    data_vol_tnv['cut_class']=data_vol_tnv.apply(lambda df: is_cut_class(df['school_time'],\n",
    "df['date_in_week'],tnv),axis=1)\n",
    "    data_vol_tnv['class_schedule']=data_vol_tnv.apply(lambda df: time_to_learn(\n",
    "df['date_in_week'],tnv),axis=1)\n",
    "    data_vol_tnv=data_vol_tnv.set_index('date')\n",
    "    data_vol_tnv['volunteer']=[tnv]*data_vol_tnv.shape[0]\n",
    "\n",
    "    data_vol_tnv=pd.concat([data_vol_tnv,location_names],axis=1)\n",
    "    data_vol_tnv=data_vol_tnv.fillna(0) \n",
    "    print(data_vol_tnv)\n",
    "    data_vol_tnv.to_csv(f'./final_data/{tnv}_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b27c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vol_tnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028d25c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dd85eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26cae8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cac571",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c05d5d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
